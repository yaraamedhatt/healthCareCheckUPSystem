{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "78CfyU0-S9uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97987beb-9afd-4ec9-c707-7d7b437c9e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjGE1ggdTQlZ",
        "outputId": "f54c1ecc-18b1-4c95-f1f4-cc4769db3baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Collecting keras-ocr\n",
            "  Downloading keras_ocr-0.8.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras-ocr)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras-ocr)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.40.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n",
            "Collecting pyclipper (from keras-ocr)\n",
            "  Downloading pyclipper-1.3.0.post4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.9/813.9 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.65.0)\n",
            "Collecting validators (from keras-ocr)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras-ocr)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.25.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators->keras-ocr) (4.4.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.8.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=dc4cf9c1146a9d8ba7c09b18e7723473399dff195347a0b36159261910e1b376\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: pyclipper, essential_generators, validators, keras-applications, efficientnet, keras-ocr\n",
            "Successfully installed efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras-ocr-0.8.9 pyclipper-1.3.0.post4 validators-0.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders\n",
        "#!pip install tflearn\n",
        "#!pip install helpers\n",
        "!pip install keras-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0Jfkesw7W0Z8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aS012baDTY7g"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/Colab Notebooks/Train_Data/Train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o5VkjQyVTefB"
      },
      "outputs": [],
      "source": [
        "def create_label(image_name):\n",
        "    word_label = image_name.split('.')[0]\n",
        "    label = word_label.split('(')[0]\n",
        "    if label == 'Acne-Rosacea ':  # 0\n",
        "        return np.array([1 , 0 , 0 , 0])\n",
        "    elif label == 'Eczema ':  # 1\n",
        "        return np.array([0 , 1 , 0 , 0])\n",
        "    elif label == 'Psoriasis-Relatives ':  # 2\n",
        "        return np.array([0 , 0 , 1 , 0])\n",
        "    elif label == 'Vitiligo ':  # 3\n",
        "        return np.array([0 , 0 , 0 , 1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_u3ljGTi3M",
        "outputId": "08e2c85a-db53-49e0-8629-723bb0733cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2636 files [00:52, 49.89 files/s] \n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "train_paths='/content/drive/MyDrive/Colab Notebooks/Train_Data'\n",
        "splitfolders.ratio(train_paths, output=\"Output\", seed=1337, ratio=(.8, .2), group_prefix=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vqRmcRVmWd9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c4fc7d-5133-4dbf-ecfe-78dac143a33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ],
      "source": [
        "train_path='/content/Output/train/Train'\n",
        "valid_path='/content/Output/val/Train'\n",
        "size=64\n",
        "def create_train_data():\n",
        "    training_data = []\n",
        "    for img in os.listdir(train_path):\n",
        "        path = os.path.join(train_path, img)\n",
        "        img_data = cv2.imread(path,3)\n",
        "        image_resize = cv2.resize(img_data,(size,size))\n",
        "        image=cv2.cvtColor(image_resize, cv2.COLOR_BGR2RGB)\n",
        "        training_data.append([np.array(image), create_label(img)])\n",
        "    shuffle(training_data)\n",
        "    np.save('trainings_data.npy', training_data)\n",
        "    return training_data\n",
        "\n",
        "def create_valid_data():\n",
        "    validing_data=[]\n",
        "    for img in os.listdir(valid_path):\n",
        "        path = os.path.join(valid_path, img)\n",
        "        img_data = cv2.imread(path,3)\n",
        "        image_resize = cv2.resize(img_data,(size,size))\n",
        "        image=cv2.cvtColor(image_resize, cv2.COLOR_BGR2RGB)\n",
        "        validing_data.append([np.array(image), create_label(img)])\n",
        "    shuffle(validing_data)\n",
        "    np.save('validating_data.npy', validing_data)\n",
        "    return validing_data\n",
        "if (os.path.exists('training_data.npy')): # If you have already created the dataset:\n",
        "    train_data =np.load('training_data.npy',allow_pickle=True)\n",
        "else: # If dataset is not created:\n",
        "    train_data = create_train_data()\n",
        "\n",
        "#print(train_data.shape)\n",
        "if (os.path.exists('validating_data.npy')):\n",
        "    val_data =np.load('validating_data.npy',allow_pickle=True)\n",
        "else:\n",
        "    val_data = create_valid_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DxauN5NxDsiu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = train_data\n",
        "valid = val_data\n",
        "num_classes=4\n",
        "Xtrain = np.array([i[0] for i in train]).reshape(-3,size,size,3)\n",
        "ytrain = np.array([i[1] for i in train])\n",
        "X_train=np.asarray(Xtrain).astype(np.float32)\n",
        "y_train=np.asarray(ytrain).astype(np.float32)\n",
        "\n",
        "\n",
        "Xvalid = np.array([i[0] for i in valid]).reshape(-3,size,size,3)\n",
        "yvalid = np.array([i[1] for i in valid])\n",
        "X_valid=np.asarray(Xvalid).astype(np.float32)\n",
        "y_valid=np.asarray(yvalid).astype(np.float32)\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid / 255.0\n",
        "mean = np.mean(X_train, axis=0)\n",
        "X_train -= mean\n",
        "X_valid -= mean\n",
        "                                # Step 2\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_valid = lb.transform(y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZN1nXRlowbW",
        "outputId": "eab91074-50f7-46cc-d48d-0200fd45f9b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2108, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D6lHm6PuaT6o"
      },
      "outputs": [],
      "source": [
        "def conv_module(input,No_of_filters,filtersizeX,filtersizeY,stride,chanDim,padding=\"same\"):\n",
        "  input = Conv2D(No_of_filters,(filtersizeX,filtersizeY),strides=stride,padding=padding)(input)\n",
        "  input = BatchNormalization(axis=chanDim)(input)\n",
        "  input = Activation(\"relu\")(input)\n",
        "  return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fa48YPSIaU0h"
      },
      "outputs": [],
      "source": [
        "def inception_module(input,numK1x1,numK3x3,numk5x5,numPoolProj,chanDim):\n",
        "                                 #Step 1\n",
        "  conv_1x1 = conv_module(input, numK1x1, 1, 1,(1, 1), chanDim)\n",
        "                                 #Step 2\n",
        "  conv_3x3 = conv_module(input, numK3x3, 3, 3,(1, 1), chanDim)\n",
        "  conv_5x5 = conv_module(input, numk5x5, 5, 5,(1, 1), chanDim)\n",
        "                                 #Step 3\n",
        "  pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
        "  pool_proj = Conv2D(numPoolProj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
        "                                 #Step 4\n",
        "  input = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=chanDim)\n",
        "  return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Dp5bjFF3afs6"
      },
      "outputs": [],
      "source": [
        "def downsample_module(input,No_of_filters,chanDim):\n",
        "  conv_3x3=conv_module(input,No_of_filters,3,3,(2,2),chanDim,padding=\"valid\")\n",
        "  pool = MaxPooling2D((3,3),strides=(2,2))(input)\n",
        "  input = concatenate([conv_3x3,pool],axis=chanDim)\n",
        "  return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gEd2wHNQap3y"
      },
      "outputs": [],
      "source": [
        "def GoogleNet(width,height,depth,classes):\n",
        "  inputShape=(height,width,depth)\n",
        "  chanDim=-1\n",
        "\n",
        "  # (Step 1) Define the model input\n",
        "  inputs = Input(shape=inputShape)\n",
        "\n",
        "  # First CONV module\n",
        "  x = conv_module(inputs, 96, 3, 3, (1, 1),chanDim)\n",
        "\n",
        "  # (Step 2) Two Inception modules followed by a downsample module\n",
        "  x = inception_module(x, 32, 32,32,32,chanDim)\n",
        "  x = inception_module(x, 32, 48, 48,32,chanDim)\n",
        "  x = downsample_module(x, 80, chanDim)\n",
        "\n",
        "  # (Step 3) Five Inception modules followed by a downsample module\n",
        "  x = inception_module(x, 112, 48, 32, 48,chanDim)\n",
        "  x = inception_module(x, 96, 64, 32,32,chanDim)\n",
        "  x = inception_module(x, 80, 80, 32,32,chanDim)\n",
        "  x = inception_module(x, 48, 96, 32,32,chanDim)\n",
        "  x = inception_module(x, 112, 48, 32, 48,chanDim)\n",
        "  x = downsample_module(x, 96, chanDim)\n",
        "\n",
        "  # (Step 4) Two Inception modules followed\n",
        "  x = inception_module(x, 176, 160,96,96, chanDim)\n",
        "  x = inception_module(x, 176, 160, 96,96,chanDim)\n",
        "\n",
        "  # Global POOL and dropout\n",
        "  x = AveragePooling2D((7, 7))(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "\n",
        "  # (Step 5) Softmax classifier\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(classes)(x)\n",
        "  x = Activation(\"softmax\")(x)\n",
        "\n",
        "  # Create the model\n",
        "  model = Model(inputs, x, name=\"googlenet\")\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZBflbZ5CcUsb"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 100\n",
        "INIT_LR = 5e-3\n",
        "def poly_decay(epoch):\n",
        "  maxEpochs = NUM_EPOCHS\n",
        "  baseLR = INIT_LR\n",
        "  power = 1.0\n",
        "  alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
        "  return alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i1CvziPgc2Az"
      },
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1, horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpTmErHodJJp",
        "outputId": "29090c11-be28-4020-dd53-93597d5e968e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"googlenet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 96)   2688        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 64, 96)  384         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 64, 96)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 64, 32)   3104        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 64, 64, 32)   27680       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 32)   76832       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 96)   0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 32)   3104        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 128)  0           ['activation_1[0][0]',           \n",
            "                                                                  'activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]',           \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 32)   4128        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 48)   55344       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 48)   153648      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 48)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 32)   4128        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 160)  0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]',           \n",
            "                                                                  'activation_6[0][0]',           \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 31, 31, 80)   115280      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 31, 31, 80)  320         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 31, 31, 80)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 31, 31, 160)  0          ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 31, 31, 240)  0           ['activation_7[0][0]',           \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 31, 31, 112)  26992       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 31, 31, 48)   103728      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 31, 31, 32)   192032      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 31, 31, 112)  448        ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 31, 31, 48)  192         ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 31, 31, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 31, 31, 240)  0          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 31, 31, 112)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 31, 31, 48)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 31, 31, 32)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 31, 31, 48)   11568       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 31, 31, 240)  0           ['activation_8[0][0]',           \n",
            "                                                                  'activation_9[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 31, 31, 96)   23136       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 31, 31, 64)   138304      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 31, 31, 32)   192032      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 31, 31, 96)  384         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 31, 31, 64)  256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 31, 31, 32)  128         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 31, 31, 240)  0          ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 31, 31, 96)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 31, 31, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 31, 31, 32)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 31, 31, 32)   7712        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 31, 31, 224)  0           ['activation_11[0][0]',          \n",
            "                                                                  'activation_12[0][0]',          \n",
            "                                                                  'activation_13[0][0]',          \n",
            "                                                                  'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 31, 31, 80)   18000       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 31, 31, 80)   161360      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 31, 31, 32)   179232      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 31, 31, 80)  320         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 31, 31, 80)  320         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 31, 31, 32)  128         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 31, 31, 224)  0          ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 31, 31, 80)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 31, 31, 80)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 31, 31, 32)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 31, 31, 32)   7200        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 31, 31, 224)  0           ['activation_14[0][0]',          \n",
            "                                                                  'activation_15[0][0]',          \n",
            "                                                                  'activation_16[0][0]',          \n",
            "                                                                  'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 31, 31, 48)   10800       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 31, 31, 96)   193632      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 31, 31, 32)   179232      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 31, 31, 48)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 31, 31, 96)  384         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 31, 31, 32)  128         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 31, 31, 224)  0          ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 31, 31, 48)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 31, 31, 96)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 31, 31, 32)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 31, 31, 32)   7200        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 31, 31, 208)  0           ['activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]',          \n",
            "                                                                  'activation_19[0][0]',          \n",
            "                                                                  'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 31, 31, 112)  23408       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 31, 31, 48)   89904       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 31, 31, 32)   166432      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 31, 31, 112)  448        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 31, 31, 48)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 31, 31, 32)  128         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 31, 31, 208)  0          ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 31, 31, 112)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 31, 31, 48)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 31, 31, 32)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 31, 31, 48)   10032       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 31, 31, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_22[0][0]',          \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 15, 15, 96)   207456      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 15, 15, 96)  384         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 15, 15, 240)  0          ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 15, 15, 336)  0           ['activation_23[0][0]',          \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 15, 15, 176)  59312       ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 15, 15, 160)  484000      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 15, 15, 96)   806496      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 15, 15, 176)  704        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 15, 15, 160)  640        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 15, 15, 96)  384         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 15, 15, 336)  0          ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 15, 15, 176)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 15, 15, 160)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 15, 15, 96)   32352       ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 15, 15, 528)  0           ['activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]',          \n",
            "                                                                  'activation_26[0][0]',          \n",
            "                                                                  'conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 15, 15, 176)  93104       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 15, 15, 160)  760480      ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 15, 15, 96)   1267296     ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 15, 15, 176)  704        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 15, 15, 160)  640        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 15, 15, 96)  384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 15, 15, 528)  0          ['concatenate_9[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 15, 15, 176)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 15, 15, 160)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 15, 15, 96)   50784       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 15, 15, 528)  0           ['activation_27[0][0]',          \n",
            "                                                                  'activation_28[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 2, 2, 528)   0           ['concatenate_10[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2, 2, 528)    0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2112)         0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            8452        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 4)            0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,966,820\n",
            "Trainable params: 5,962,212\n",
            "Non-trainable params: 4,608\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "callbacks=[LearningRateScheduler(poly_decay)]\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "model = GoogleNet(width=size, height=size, depth=3, classes=4)\n",
        "                                    # Step 1\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "                                    # Step 2\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiYU7vvVdTzL",
        "outputId": "0b0692b7-0fc6-4418-bce6-a0f45f2ca47c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - ETA: 0s - batch: 24.5000 - size: 63.9200 - loss: 1.3948 - acc: 0.5078"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 66s 783ms/step - batch: 24.5000 - size: 63.9200 - loss: 1.3948 - acc: 0.5078 - val_loss: 1.4134 - val_acc: 0.3883 - lr: 0.0050\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 27s 536ms/step - batch: 24.5000 - size: 63.8400 - loss: 1.0282 - acc: 0.6071 - val_loss: 1.4801 - val_acc: 0.3580 - lr: 0.0049\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 28s 569ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.8794 - acc: 0.6652 - val_loss: 1.7434 - val_acc: 0.3220 - lr: 0.0049\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 27s 548ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.8287 - acc: 0.6751 - val_loss: 1.9242 - val_acc: 0.3220 - lr: 0.0049\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 27s 549ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.8004 - acc: 0.6824 - val_loss: 1.7102 - val_acc: 0.3352 - lr: 0.0048\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.7230 - acc: 0.7171 - val_loss: 1.4231 - val_acc: 0.3864 - lr: 0.0047\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.7021 - acc: 0.7178 - val_loss: 1.3740 - val_acc: 0.4640 - lr: 0.0047\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 28s 552ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.6887 - acc: 0.7215 - val_loss: 1.1250 - val_acc: 0.5549 - lr: 0.0047\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 28s 553ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.6715 - acc: 0.7297 - val_loss: 0.7772 - val_acc: 0.6913 - lr: 0.0046\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.6296 - acc: 0.7425 - val_loss: 0.6946 - val_acc: 0.7083 - lr: 0.0046\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.6116 - acc: 0.7541 - val_loss: 0.6349 - val_acc: 0.7424 - lr: 0.0045\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 32s 634ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.5913 - acc: 0.7622 - val_loss: 0.6486 - val_acc: 0.7102 - lr: 0.0044\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.5794 - acc: 0.7660 - val_loss: 0.6066 - val_acc: 0.7614 - lr: 0.0044\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.5668 - acc: 0.7678 - val_loss: 0.6069 - val_acc: 0.7652 - lr: 0.0044\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 28s 552ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.5291 - acc: 0.7901 - val_loss: 0.5857 - val_acc: 0.7803 - lr: 0.0043\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.5385 - acc: 0.7910 - val_loss: 0.6573 - val_acc: 0.7860 - lr: 0.0043\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.5455 - acc: 0.7838 - val_loss: 0.5940 - val_acc: 0.7595 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.5116 - acc: 0.7939 - val_loss: 0.6492 - val_acc: 0.7500 - lr: 0.0041\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.4895 - acc: 0.7957 - val_loss: 0.6916 - val_acc: 0.7424 - lr: 0.0041\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.4787 - acc: 0.8089 - val_loss: 0.6219 - val_acc: 0.7614 - lr: 0.0041\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.4578 - acc: 0.8157 - val_loss: 1.0755 - val_acc: 0.6515 - lr: 0.0040\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.4634 - acc: 0.8170 - val_loss: 0.6983 - val_acc: 0.7462 - lr: 0.0039\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.4478 - acc: 0.8208 - val_loss: 0.7451 - val_acc: 0.7008 - lr: 0.0039\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 28s 553ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.4330 - acc: 0.8283 - val_loss: 0.5917 - val_acc: 0.7784 - lr: 0.0038\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 64.0000 - loss: 0.4507 - acc: 0.8150 - val_loss: 0.6459 - val_acc: 0.7557 - lr: 0.0038\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 28s 552ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.4295 - acc: 0.8271 - val_loss: 0.6677 - val_acc: 0.7784 - lr: 0.0037\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3979 - acc: 0.8443 - val_loss: 0.6245 - val_acc: 0.7898 - lr: 0.0037\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 28s 553ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3794 - acc: 0.8493 - val_loss: 0.5933 - val_acc: 0.8011 - lr: 0.0037\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.4078 - acc: 0.8323 - val_loss: 0.5814 - val_acc: 0.7841 - lr: 0.0036\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3747 - acc: 0.8571 - val_loss: 0.5705 - val_acc: 0.7917 - lr: 0.0036\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.4116 - acc: 0.8373 - val_loss: 0.6707 - val_acc: 0.7784 - lr: 0.0035\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.3558 - acc: 0.8623 - val_loss: 0.5818 - val_acc: 0.7992 - lr: 0.0034\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3634 - acc: 0.8587 - val_loss: 0.6876 - val_acc: 0.7917 - lr: 0.0034\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3190 - acc: 0.8741 - val_loss: 0.6458 - val_acc: 0.7879 - lr: 0.0033\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.3280 - acc: 0.8698 - val_loss: 0.6269 - val_acc: 0.7992 - lr: 0.0033\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3456 - acc: 0.8640 - val_loss: 0.7509 - val_acc: 0.7614 - lr: 0.0033\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 28s 552ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.3094 - acc: 0.8714 - val_loss: 0.6804 - val_acc: 0.7519 - lr: 0.0032\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.3249 - acc: 0.8741 - val_loss: 0.6092 - val_acc: 0.7992 - lr: 0.0032\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.2864 - acc: 0.8883 - val_loss: 0.6067 - val_acc: 0.7955 - lr: 0.0031\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2886 - acc: 0.8875 - val_loss: 0.7826 - val_acc: 0.7292 - lr: 0.0030\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 28s 553ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.3132 - acc: 0.8874 - val_loss: 0.7213 - val_acc: 0.7386 - lr: 0.0030\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.2743 - acc: 0.8958 - val_loss: 0.5570 - val_acc: 0.8201 - lr: 0.0030\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2580 - acc: 0.9054 - val_loss: 0.6865 - val_acc: 0.8106 - lr: 0.0029\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2707 - acc: 0.9023 - val_loss: 0.6040 - val_acc: 0.8295 - lr: 0.0029\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.2620 - acc: 0.9058 - val_loss: 1.1533 - val_acc: 0.7121 - lr: 0.0028\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.2638 - acc: 0.9024 - val_loss: 0.7867 - val_acc: 0.7992 - lr: 0.0027\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2257 - acc: 0.9170 - val_loss: 0.9295 - val_acc: 0.7576 - lr: 0.0027\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.2306 - acc: 0.9127 - val_loss: 0.6253 - val_acc: 0.8201 - lr: 0.0026\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2101 - acc: 0.9248 - val_loss: 0.6949 - val_acc: 0.8125 - lr: 0.0026\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.2226 - acc: 0.9135 - val_loss: 0.6351 - val_acc: 0.8182 - lr: 0.0026\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1985 - acc: 0.9293 - val_loss: 0.6065 - val_acc: 0.8371 - lr: 0.0025\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1927 - acc: 0.9270 - val_loss: 0.6977 - val_acc: 0.8295 - lr: 0.0025\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1858 - acc: 0.9246 - val_loss: 0.7888 - val_acc: 0.8011 - lr: 0.0024\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1823 - acc: 0.9311 - val_loss: 0.6224 - val_acc: 0.8314 - lr: 0.0023\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1902 - acc: 0.9265 - val_loss: 0.7646 - val_acc: 0.8239 - lr: 0.0023\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1603 - acc: 0.9392 - val_loss: 0.6917 - val_acc: 0.8277 - lr: 0.0022\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1764 - acc: 0.9298 - val_loss: 0.6561 - val_acc: 0.8295 - lr: 0.0022\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1547 - acc: 0.9456 - val_loss: 0.8140 - val_acc: 0.8030 - lr: 0.0022\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1585 - acc: 0.9439 - val_loss: 0.7659 - val_acc: 0.7936 - lr: 0.0021\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 64.0000 - loss: 0.1567 - acc: 0.9409 - val_loss: 0.8653 - val_acc: 0.8182 - lr: 0.0021\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1350 - acc: 0.9511 - val_loss: 0.7090 - val_acc: 0.8087 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1473 - acc: 0.9417 - val_loss: 0.6988 - val_acc: 0.8239 - lr: 0.0019\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1248 - acc: 0.9571 - val_loss: 0.6830 - val_acc: 0.8295 - lr: 0.0019\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1302 - acc: 0.9506 - val_loss: 0.8122 - val_acc: 0.8011 - lr: 0.0019\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1187 - acc: 0.9571 - val_loss: 0.7875 - val_acc: 0.8125 - lr: 0.0018\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1216 - acc: 0.9528 - val_loss: 0.8127 - val_acc: 0.8220 - lr: 0.0018\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 28s 553ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1249 - acc: 0.9546 - val_loss: 0.7034 - val_acc: 0.8220 - lr: 0.0017\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1138 - acc: 0.9593 - val_loss: 0.7790 - val_acc: 0.8144 - lr: 0.0016\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.1151 - acc: 0.9553 - val_loss: 0.6844 - val_acc: 0.8371 - lr: 0.0016\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.1217 - acc: 0.9549 - val_loss: 0.8292 - val_acc: 0.8390 - lr: 0.0016\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0923 - acc: 0.9680 - val_loss: 0.8385 - val_acc: 0.8333 - lr: 0.0015\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0867 - acc: 0.9693 - val_loss: 0.7532 - val_acc: 0.8485 - lr: 0.0014\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0707 - acc: 0.9737 - val_loss: 0.7344 - val_acc: 0.8182 - lr: 0.0014\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0714 - acc: 0.9737 - val_loss: 0.7254 - val_acc: 0.8598 - lr: 0.0014\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0824 - acc: 0.9718 - val_loss: 0.7190 - val_acc: 0.8466 - lr: 0.0013\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0588 - acc: 0.9822 - val_loss: 0.6850 - val_acc: 0.8390 - lr: 0.0012\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0664 - acc: 0.9740 - val_loss: 0.9385 - val_acc: 0.8220 - lr: 0.0012\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0712 - acc: 0.9778 - val_loss: 0.7392 - val_acc: 0.8371 - lr: 0.0012\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0662 - acc: 0.9768 - val_loss: 0.7042 - val_acc: 0.8333 - lr: 0.0011\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0568 - acc: 0.9815 - val_loss: 0.7112 - val_acc: 0.8428 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0505 - acc: 0.9831 - val_loss: 0.7386 - val_acc: 0.8371 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 28s 554ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0440 - acc: 0.9872 - val_loss: 0.7614 - val_acc: 0.8504 - lr: 9.5000e-04\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0468 - acc: 0.9840 - val_loss: 0.8229 - val_acc: 0.8447 - lr: 9.0000e-04\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0442 - acc: 0.9840 - val_loss: 0.7199 - val_acc: 0.8485 - lr: 8.5000e-04\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0388 - acc: 0.9897 - val_loss: 0.7812 - val_acc: 0.8409 - lr: 8.0000e-04\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0411 - acc: 0.9875 - val_loss: 0.7126 - val_acc: 0.8542 - lr: 7.5000e-04\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0438 - acc: 0.9837 - val_loss: 0.7136 - val_acc: 0.8333 - lr: 7.0000e-04\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0398 - acc: 0.9865 - val_loss: 0.7883 - val_acc: 0.8485 - lr: 6.5000e-04\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0420 - acc: 0.9893 - val_loss: 0.6657 - val_acc: 0.8504 - lr: 6.0000e-04\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0390 - acc: 0.9869 - val_loss: 0.7378 - val_acc: 0.8561 - lr: 5.5000e-04\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0357 - acc: 0.9872 - val_loss: 0.7097 - val_acc: 0.8466 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0371 - acc: 0.9897 - val_loss: 0.7445 - val_acc: 0.8485 - lr: 4.5000e-04\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0312 - acc: 0.9887 - val_loss: 0.7401 - val_acc: 0.8523 - lr: 4.0000e-04\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0263 - acc: 0.9915 - val_loss: 0.7001 - val_acc: 0.8504 - lr: 3.5000e-04\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 28s 557ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0283 - acc: 0.9915 - val_loss: 0.7190 - val_acc: 0.8504 - lr: 3.0000e-04\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0264 - acc: 0.9928 - val_loss: 0.7090 - val_acc: 0.8504 - lr: 2.5000e-04\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 28s 558ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0255 - acc: 0.9934 - val_loss: 0.7320 - val_acc: 0.8504 - lr: 2.0000e-04\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0282 - acc: 0.9909 - val_loss: 0.7057 - val_acc: 0.8485 - lr: 1.5000e-04\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 28s 555ms/step - batch: 24.5000 - size: 63.8400 - loss: 0.0270 - acc: 0.9922 - val_loss: 0.7255 - val_acc: 0.8485 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 28s 556ms/step - batch: 24.5000 - size: 63.9200 - loss: 0.0246 - acc: 0.9928 - val_loss: 0.7140 - val_acc: 0.8561 - lr: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a56eceb00>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.fit(aug.flow(X_train, y_train, batch_size=64),validation_data=(X_valid, y_valid), steps_per_epoch=50,epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWiA4iEad-42",
        "outputId": "cec478d7-f7fa-4683-a68a-6004034a1035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ],
      "source": [
        "test_path='/content/drive/MyDrive/Colab Notebooks/Test_Data/Test'\n",
        "#size=224\n",
        "images_names=[]\n",
        "def create_test_data():\n",
        "    testing_data=[]\n",
        "    for img in os.listdir(test_path):\n",
        "        path = os.path.join(test_path, img)\n",
        "        img_data = cv2.imread(path,3)\n",
        "        image_resize = cv2.resize(img_data,(size,size))\n",
        "        image=cv2.cvtColor(image_resize, cv2.COLOR_BGR2RGB)\n",
        "        testing_data.append([np.array(image), create_label(img)])\n",
        "    shuffle(testing_data)\n",
        "    np.save('testingsssss_data.npy', testing_data)\n",
        "    return testing_data\n",
        "if (os.path.exists('testingsssss_data.npy')):\n",
        "    test_data =np.load('testingsssss_data.npy',allow_pickle=True)\n",
        "else:\n",
        "    test_data = create_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LYnSNlU9eyg-"
      },
      "outputs": [],
      "source": [
        "\n",
        "test = test_data\n",
        "xtest = np.array([i[0] for i in test]).reshape(-3,size,size,3)\n",
        "ytest = np.array([i[1] for i in test])\n",
        "X_test=np.asarray(xtest).astype(np.float32)\n",
        "y_test=np.asarray(ytest).astype(np.float32)\n",
        "X_test = X_test / 255.0\n",
        "mean = np.mean(X_test, axis=0)\n",
        "X_test -= mean                  # Step 2\n",
        "lb = LabelBinarizer()\n",
        "y_test = lb.fit_transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_716acXB5sa",
        "outputId": "e9a0aac4-4ce6-4aa0-dc07-5f15645bfd71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy= 0.904325\n"
          ]
        }
      ],
      "source": [
        "score=model.evaluate(X_test,y_test)\n",
        "print('Test Accuracy=',score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}